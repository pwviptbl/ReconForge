#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Agente IA Centralizado - Fase 2
Implementa um agente aut√¥nomo usando Gemini e aprendizado de m√°quina
para decis√µes inteligentes e adapt√°veis
"""

import json
import re
import time
from typing import Dict, Any, List, Optional, Union
from dataclasses import dataclass, field

# Importa√ß√µes para Gemini
try:
    import google.generativeai as genai
    GEMINI_DISPONIVEL = True
except ImportError:
    GEMINI_DISPONIVEL = False

# Importa√ß√£o do sistema de aprendizado de m√°quina
from historico_ia.gerenciador_historico import obter_aprendizado_maquina


@dataclass
class EstadoAgente:
    """Estado atual do agente IA"""
    contexto_atual: Dict[str, Any] = field(default_factory=dict)
    decisoes_anteriores: List[Dict] = field(default_factory=list)
    modulos_executados: List[str] = field(default_factory=list)
    pontuacao_risco: int = 0
    iteracao_atual: int = 0
    finalizado: bool = False


class AgenteIACentral:
    """Agente IA centralizado usando Gemini para decis√µes aut√¥nomas"""

    def __init__(self, config_ia: Dict[str, Any], logger_func=None):
        self.logger = logger_func if logger_func else print
        self.config = config_ia
        self.estado = EstadoAgente()
        
        # Inicializar sistema de aprendizado de m√°quina
        try:
            self.ml = obter_aprendizado_maquina()
            self.ml_disponivel = True
            self.log("‚úÖ Sistema de aprendizado de m√°quina inicializado")
            
            # Carregar modelos existentes ou treinar novos se necess√°rio
            self._inicializar_ml()
        except Exception as e:
            self.ml_disponivel = False
            self.log(f"‚ö†Ô∏è Sistema de aprendizado de m√°quina n√£o dispon√≠vel: {e}")

        # Verificar se temos chave API do Gemini
        if not self.config.get('chave_api'):
            raise ValueError("‚ùå Agente IA Central requer chave API do Gemini. Configure em config/default.yaml")

        # Inicializar conex√£o com Gemini
        self._inicializar_gemini()

        self.log("‚úÖ Agente IA Central inicializado com Gemini e Aprendizado de M√°quina")
    
    def log(self, mensagem: str):
        """M√©todo auxiliar para log uniforme"""
        if callable(self.logger):
            self.logger(mensagem)
        else:
            print(mensagem)

    def _inicializar_ml(self):
        """Inicializa o sistema de aprendizado de m√°quina"""
        if not self.ml_disponivel:
            return
        
        try:
            # Tentar carregar modelos existentes
            resultado_carregamento = self.ml.carregar_modelos_salvos()
            
            if not resultado_carregamento or 'erro' in resultado_carregamento:
                self.log("‚ö†Ô∏è Nenhum modelo encontrado. Carregando dados para treinamento...")
                
                # Processar dados
                df = self.ml.carregar_e_processar_dados()
                
                if df is not None and not df.empty:
                    self.log(f"‚úÖ Dados carregados com sucesso: {len(df)} registros")
                    
                    # Treinar modelos
                    self.log("üß† Treinando modelos de aprendizado de m√°quina...")
                    resultados = self.ml.treinar_modelos()
                    
                    if resultados:
                        self.log("‚úÖ Modelos treinados com sucesso")
                    else:
                        self.log("‚ö†Ô∏è N√£o foi poss√≠vel treinar os modelos")
            else:
                self.log(f"‚úÖ Modelos carregados: {', '.join(k for k, v in resultado_carregamento.items() if v == 'carregado')}")
                
            # Analisar tend√™ncias
            try:
                tendencias = self.ml.analisar_tendencias()
                if tendencias and 'erro' not in tendencias:
                    self.log(f"üìä An√°lise de tend√™ncias: Taxa de sucesso {tendencias.get('tendencia_sucesso', {}).get('taxa_atual', 0)}%")
            except:
                pass
                
        except Exception as e:
            self.log(f"‚ö†Ô∏è Erro ao inicializar sistema ML: {e}")
            self.ml_disponivel = False
    
    def _inicializar_gemini(self):
        """Inicializa a conex√£o com Gemini"""
        if not GEMINI_DISPONIVEL:
            raise ImportError("‚ùå google-generativeai n√£o est√° instalado. Instale com: pip install google-generativeai")

        try:
            genai.configure(api_key=self.config['chave_api'])
            self.modelo = genai.GenerativeModel(
                model_name=self.config.get('modelo_principal', 'gemini-2.5-flash'),
                generation_config={
                    'temperature': self.config.get('temperatura', 0.3),
                    'max_output_tokens': self.config.get('contexto_max_tokens', 4000),
                }
            )

            # Teste de conex√£o
            teste_response = self.modelo.generate_content("Responda apenas: OK")
            if not teste_response or not hasattr(teste_response, 'text'):
                raise ConnectionError("‚ùå Falha na resposta de teste do Gemini")

        except Exception as e:
            raise ConnectionError(f"‚ùå Erro ao conectar com Gemini: {e}")

    def _consultar_gemini(self, prompt: str) -> str:
        """Consulta o Gemini com o prompt fornecido"""
        try:
            response = self.modelo.generate_content(prompt)
            if response and hasattr(response, 'text'):
                return response.text.strip()
            else:
                raise ValueError("Resposta inv√°lida do Gemini")
        except Exception as e:
            if callable(self.logger):
                self.logger(f"‚ùå Erro na consulta Gemini: {e}")
            else:
                print(f"‚ùå Erro na consulta Gemini: {e}")
            raise

    def tomar_decisao(self, contexto_atual: Dict[str, Any], modulos_disponiveis: List[str]) -> Dict[str, Any]:
        """
        Toma decis√£o aut√¥noma baseada no contexto usando Gemini e aprendizado de m√°quina
        Fase 2: Combina decis√µes de IA com recomenda√ß√µes de ML
        """
        self.estado.contexto_atual = contexto_atual
        self.estado.iteracao_atual += 1
        
        # Obter recomenda√ß√µes do sistema ML (se dispon√≠vel)
        recomendacao_ml = self._obter_recomendacao_ml(contexto_atual, modulos_disponiveis)
        
        # Incluir recomenda√ß√µes de ML no contexto para o Gemini
        prompt = self._criar_prompt_decisao(contexto_atual, modulos_disponiveis, recomendacao_ml)

        try:
            # Consultar Gemini
            inicio = time.time()
            resposta_gemini = self._consultar_gemini(prompt)
            tempo_resposta = time.time() - inicio

            # Parse da resposta
            decisao = self._parse_resposta_gemini(resposta_gemini)
            
            # Adicionar metadados do ML
            if recomendacao_ml:
                decisao['metadados_ml'] = {
                    'recomendacao_usada': decisao.get('modulo') in recomendacao_ml.get('modulos_sugeridos', []),
                    'confianca_ml': recomendacao_ml.get('confianca', 'baixa')
                }

            # Registrar decis√£o
            self.estado.decisoes_anteriores.append(decisao)
            self.log(f"üß† Agente h√≠brido decidiu: {decisao.get('acao')} - {decisao.get('modulo', '')}")
            
            # Feedback para o sistema de ML (para aprendizado cont√≠nuo)
            self._registrar_feedback_ml(decisao, contexto_atual, tempo_resposta)

            return decisao

        except Exception as e:
            # Em caso de erro, usar recomenda√ß√µes de ML ou decis√£o padr√£o
            self.log(f"‚ùå Erro na decis√£o IA: {e}. Tentando usar recomenda√ß√£o ML.")
            
            if recomendacao_ml and 'modulos_sugeridos' in recomendacao_ml and recomendacao_ml['modulos_sugeridos']:
                modulo_sugerido = recomendacao_ml['modulos_sugeridos'][0]
                return {
                    'acao': 'executar_modulo',
                    'modulo': modulo_sugerido,
                    'justificativa': 'Decis√£o baseada em aprendizado de m√°quina (fallback)',
                    'prioridade': 'media',
                    'expectativa': 'Seguindo padr√£o hist√≥rico de sucesso',
                    'origem': 'ml_fallback'
                }
            else:
                return self._decisao_padrao()
    
    def _obter_recomendacao_ml(self, contexto: Dict[str, Any], modulos_disponiveis: List[str]) -> Dict[str, Any]:
        """
        Obt√©m recomenda√ß√µes do sistema de aprendizado de m√°quina
        """
        if not self.ml_disponivel:
            return {}
        
        try:
            # Filtrar m√≥dulos que j√° foram executados
            modulos_executados = contexto.get('modulos_executados', [])
            modulos_disponiveis_filtrados = [m for m in modulos_disponiveis if m not in modulos_executados]
            
            if not modulos_disponiveis_filtrados:
                return {'sugestao': 'parar', 'motivo': 'Todos os m√≥dulos j√° foram executados'}
            
            # Pedir sugest√£o ao sistema ML
            sugestao = self.ml.sugerir_modulos(contexto)
            
            # Verificar se as sugest√µes est√£o na lista de m√≥dulos dispon√≠veis
            if sugestao and 'modulos_sugeridos' in sugestao:
                sugestao['modulos_sugeridos'] = [
                    m for m in sugestao['modulos_sugeridos'] 
                    if m in modulos_disponiveis_filtrados
                ]
            
            # Checar se o sistema ML detecta anomalias no padr√£o atual
            try:
                # Converter contexto para formato compat√≠vel
                dados_contexto = {
                    'num_modulos': len(contexto.get('modulos_executados', [])),
                    'ips_descobertos': len(contexto.get('ips_descobertos', [])),
                    'total_portas': sum(len(portas) for portas in contexto.get('portas_abertas', {}).values()),
                    'vulnerabilidades': len(contexto.get('vulnerabilidades_encontradas', [])),
                }
                
                anomalia = self.ml.detectar_anomalias(dados_contexto)
                if anomalia and 'anomalia_detectada' in anomalia:
                    sugestao['anomalia'] = anomalia
            except:
                pass
            
            return sugestao
        except Exception as e:
            self.log(f"‚ö†Ô∏è Erro ao obter recomenda√ß√£o ML: {e}")
            return {}

    def _criar_prompt_decisao(self, contexto: Dict[str, Any], modulos_disponiveis: List[str], 
                         recomendacao_ml: Dict[str, Any] = None) -> str:
        """Cria o prompt para consulta ao Gemini, incluindo recomenda√ß√µes de ML"""
        # Usar o contexto passado em vez do estado interno para evitar dessincroniza√ß√£o
        modulos_executados = contexto.get('modulos_executados', [])
        pontuacao_risco = contexto.get('pontuacao_risco', 0)
        iteracao_atual = self.estado.iteracao_atual
        
        # Se√ß√£o de recomenda√ß√µes ML (se dispon√≠vel)
        secao_ml = ""
        if recomendacao_ml and 'modulos_sugeridos' in recomendacao_ml and recomendacao_ml['modulos_sugeridos']:
            modulos_sugeridos = recomendacao_ml['modulos_sugeridos']
            confianca = recomendacao_ml.get('confianca', 'm√©dia')
            
            secao_ml = f"""
RECOMENDA√á√ïES DE APRENDIZADO DE M√ÅQUINA:
- Confian√ßa da recomenda√ß√£o: {confianca}
- M√≥dulos recomendados com base em padr√µes hist√≥ricos: {', '.join(modulos_sugeridos)}
"""
            
            # Adicionar informa√ß√µes de anomalias se dispon√≠veis
            if 'anomalia' in recomendacao_ml and recomendacao_ml['anomalia'].get('anomalia_detectada', False):
                secao_ml += f"- ALERTA: Padr√£o an√¥malo detectado na varredura atual. {recomendacao_ml['anomalia'].get('recomendacao', '')}\n"
        
        return f"""Voc√™ √© um agente de seguran√ßa cibern√©tica aut√¥nomo especializado em pentesting.
Sua miss√£o √© coordenar varreduras de vulnerabilidades de forma inteligente e segura.
Voc√™ trabalha em conjunto com um sistema de aprendizado de m√°quina que analisa padr√µes hist√≥ricos.

CONTEXTO ATUAL:
- Itera√ß√£o: {iteracao_atual}
- Pontua√ß√£o de risco: {pontuacao_risco}/100
- M√≥dulos j√° executados: {', '.join(modulos_executados) or 'Nenhum'}
- IPs descobertos: {contexto.get('ips_descobertos', [])}
- Portas abertas: {contexto.get('portas_abertas', {})}
- Servi√ßos detectados: {len(contexto.get('servicos_detectados', {}))}
- Vulnerabilidades encontradas: {len(contexto.get('vulnerabilidades_encontradas', []))}
{secao_ml}
M√ìDULOS DISPON√çVEIS:
{', '.join(modulos_disponiveis)}

INSTRU√á√ïES IMPORTANTES:
1. Sempre priorize a seguran√ßa e anonimiza√ß√£o
2. Evite a√ß√µes destrutivas ou invasivas sem justificativa clara
3. Use apenas m√≥dulos dispon√≠veis na lista acima
4. Pare quando an√°lise estiver completa ou risco for muito alto
5. Mantenha decis√µes consistentes e bem documentadas
6. EVITE REPETIR M√ìDULOS J√Å EXECUTADOS - escolha sempre m√≥dulos diferentes
7. Se j√° executou v√°rios m√≥dulos de Nmap, passe para outros tipos de an√°lise
8. CONSIDERE AS RECOMENDA√á√ïES DE ML - elas s√£o baseadas em padr√µes hist√≥ricos de sucesso

Decida o pr√≥ximo passo e responda APENAS em formato JSON:
{{
    "acao": "executar_modulo|parar",
    "modulo": "nome_do_modulo_se_aplicavel",
    "justificativa": "explica√ß√£o_da_decis√£o",
    "prioridade": "alta|media|baixa",
    "expectativa": "o_que_espera_descobrir",
    "considera_ml": "sim|parcial|nao"
}}

EXEMPLOS:
- Para iniciar descoberta: {{"acao": "executar_modulo", "modulo": "scanner_portas_python", "justificativa": "Iniciar descoberta b√°sica de portas", "prioridade": "alta", "expectativa": "Descobrir portas abertas", "considera_ml": "sim"}}
- Para an√°lise web: {{"acao": "executar_modulo", "modulo": "scanner_web_avancado", "justificativa": "Analisar vulnerabilidades web nas portas descobertas", "prioridade": "alta", "expectativa": "Encontrar vulnerabilidades web", "considera_ml": "parcial"}}
- Para parar: {{"acao": "parar", "justificativa": "An√°lise abrangente conclu√≠da", "prioridade": "baixa", "expectativa": "Nenhuma", "considera_ml": "sim"}}
"""

    def _parse_resposta_gemini(self, resposta: str) -> Dict[str, Any]:
        """Parse da resposta do Gemini para formato padronizado"""
        try:
            # Tentar encontrar JSON na resposta
            json_match = re.search(r'\{.*\}', resposta, re.DOTALL)
            if json_match:
                resposta_json = json_match.group()
                return json.loads(resposta_json)
            else:
                # Se n√£o encontrar JSON, tentar extrair informa√ß√µes
                return self._extrair_decisao_texto(resposta)

        except json.JSONDecodeError:
            # Se JSON inv√°lido, tentar extrair do texto
            return self._extrair_decisao_texto(resposta)

    def _extrair_decisao_texto(self, resposta: str) -> Dict[str, Any]:
        """Extrai decis√£o de resposta textual quando JSON falha"""
        resposta_lower = resposta.lower()

        # Verificar se deve parar
        if 'parar' in resposta_lower or 'conclu' in resposta_lower or 'final' in resposta_lower:
            return {
                'acao': 'parar',
                'justificativa': 'Decis√£o baseada na resposta do Gemini',
                'prioridade': 'baixa'
            }

        # Lista de m√≥dulos por prioridade (evitando repeti√ß√µes de Nmap)
        modulos_prioridade = [
            'scanner_vulnerabilidades',  # Prioridade alta para vulnerabilidades
            'nuclei_scan',               # Scanner de vulnerabilidades
            'scanner_web_avancado',      # An√°lise web
            'detector_tecnologias_python', # Detec√ß√£o de tecnologias
            'scanner_diretorios_python',   # Scanner de diret√≥rios
            'buscador_exploits_python',    # Busca de exploits
            'analisador_vulnerabilidades_web_python', # An√°lise web espec√≠fica
            'enumerador_subdominios_python', # Enumera√ß√£o de subdom√≠nios
            'scraper_auth',               # Web scraping com auth
            'navegador_web',              # Navega√ß√£o web
            'navegador_web_gemini',       # Navega√ß√£o com Gemini
            'sqlmap_teste_url',           # Teste SQL injection
            'sqlmap_teste_formulario'     # Teste SQL em formul√°rios
        ]

        # Verificar se algum m√≥dulo priorit√°rio √© mencionado
        for modulo in modulos_prioridade:
            if modulo.lower().replace('_', ' ') in resposta_lower or modulo in resposta_lower:
                return {
                    'acao': 'executar_modulo',
                    'modulo': modulo,
                    'justificativa': 'Decis√£o baseada na resposta do Gemini',
                    'prioridade': 'alta' if modulo in ['scanner_vulnerabilidades', 'nuclei_scan'] else 'media'
                }

        # Se nada espec√≠fico for encontrado, usar decis√£o padr√£o de parar
        return self._decisao_padrao()
        return self._decisao_padrao()

    def _decisao_padrao(self) -> Dict[str, Any]:
        """Decis√£o padr√£o quando tudo falha"""
        return {
            'acao': 'parar',
            'justificativa': 'Decis√£o padr√£o - erro na IA',
            'prioridade': 'baixa'
        }

    def atualizar_estado(self, resultado_modulo: Dict[str, Any]):
        """Atualiza estado interno com resultado de m√≥dulo"""
        modulo = resultado_modulo.get('modulo', '')
        if modulo and modulo not in self.estado.modulos_executados:
            self.estado.modulos_executados.append(modulo)
            if callable(self.logger):
                self.logger(f"Agente IA Central: m√≥dulo {modulo} registrado como executado")
            else:
                print(f"Agente IA Central: m√≥dulo {modulo} registrado como executado")

        # Atualizar pontua√ß√£o de risco baseada no resultado
        vulnerabilidades = resultado_modulo.get('vulnerabilidades', [])
        if vulnerabilidades:
            self.estado.pontuacao_risco += len(vulnerabilidades) * 10

        # Aumentar risco se o m√≥dulo foi bem-sucedido (mais informa√ß√µes = mais risco potencial)
        if resultado_modulo.get('sucesso', False):
            self.estado.pontuacao_risco += 5

        self.estado.pontuacao_risco = min(self.estado.pontuacao_risco, 100)

        if callable(self.logger):
            self.logger(f"Agente IA Central: pontua√ß√£o de risco atualizada para {self.estado.pontuacao_risco}")
        else:
            print(f"Agente IA Central: pontua√ß√£o de risco atualizada para {self.estado.pontuacao_risco}")

    def _registrar_feedback_ml(self, decisao: Dict[str, Any], contexto: Dict[str, Any], tempo_resposta: float):
        """
        Registra feedback para o sistema de ML
        Este feedback ser√° usado para melhorar as recomenda√ß√µes futuras
        """
        if not self.ml_disponivel:
            return
        
        try:
            # Converter decis√£o e contexto para formato adequado para feedback
            feedback = {
                'decisao': decisao.get('acao'),
                'modulo_escolhido': decisao.get('modulo', ''),
                'modulos_executados_anteriormente': contexto.get('modulos_executados', []),
                'total_modulos_executados': len(contexto.get('modulos_executados', [])),
                'portas_encontradas': sum(len(portas) for portas in contexto.get('portas_abertas', {}).values()),
                'vulnerabilidades_encontradas': len(contexto.get('vulnerabilidades_encontradas', [])),
                'iteracao': self.estado.iteracao_atual,
                'tempo_decisao': tempo_resposta
            }
            
            # Aqui podemos implementar a l√≥gica de feedback para melhorar o modelo
            # Por exemplo, armazenar os padr√µes de decis√£o para retreinar o modelo
            # periodicamente ou em tempo real
            
            # No futuro, podemos adicionar uma API no sistema ML para receber feedback
            pass
            
        except Exception as e:
            self.log(f"‚ö†Ô∏è Erro ao registrar feedback para ML: {e}")
    
    def finalizar(self):
        """Finaliza o agente"""
        self.estado.finalizado = True
        
        # Se tiver ML dispon√≠vel, salvar an√°lises ou treinar modelos finais
        if self.ml_disponivel:
            try:
                # Analisar tend√™ncias finais
                tendencias = self.ml.analisar_tendencias()
                if tendencias and 'erro' not in tendencias:
                    self.log(f"üìä An√°lise final de tend√™ncias: {tendencias.get('modulos_mais_utilizados', {})}")
            except:
                pass
        
        self.log("Agente IA Central finalizado")
